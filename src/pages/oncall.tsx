import { callOptions } from "../constants/call";
import OnCallLogo from "../assets/logo/oncall-logo.svg?react";
import Cancel from "../assets/logo/naver.svg?react";
import { useNavigate } from "react-router-dom";
import { useCallTimer } from "../hooks/useCallTimer";
import { formatTime } from "../utils/formatTime";
import apiRequest from "../api/apiRequest";
import { useRef, useState, useEffect } from "react";
import { MODEL } from "../constants/call";

export default function OnCallPage() {
  const navigate = useNavigate();
  const callSeconds = useCallTimer();

  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioTrackRef = useRef<MediaStreamTrack | null>(null);

  const [messages, setMessages] = useState<string[]>([]);

  const handleDataChannelMessage = (event: MessageEvent) => {
    const newMessage = event.data;
    console.log("ğŸ“© Message received:", newMessage);
    setMessages((prev) => [...prev, newMessage]);
  };

  const handleStartTranslate = async () => {
    try {
      const data = await apiRequest({
        url: `/session`,
        method: "POST",
      });

      const EPHEMERAL_KEY = data.data.client_secret.value; //ì„ì‹œ í‚¤ ë°œê¸‰

      const newPc = new RTCPeerConnection();
      pcRef.current = newPc; // ë§ˆì´í¬ ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€

      // ë§ˆì´í¬ íŠ¸ë™ ê°€ì ¸ì™€ì„œ ìš°ì„ 
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });
      const newAudioTrack = mediaStream.getAudioTracks()[0];
      newAudioTrack.enabled = false; // ì´ˆê¸°ì—ëŠ” ìŒì†Œê±° ìƒíƒœë¡œ ì„¤ì •
      audioTrackRef.current = newAudioTrack;
      newPc.addTrack(newAudioTrack, mediaStream); // ì‘ë‹µ ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì •

      // (ê¸°ì¡´) ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì •
      const audioEl = document.createElement("audio");
      audioEl.autoplay = true;
      newPc.ontrack = (event) => {
        audioEl.srcObject = event.streams[0];
      };

      // DataChannel ìƒì„±
      const newDc = newPc.createDataChannel("oai-events");
      dcRef.current = newDc;

      newDc.onmessage = handleDataChannelMessage; // Attach message handler

      // DataChannel open ì‹œì ì— "ì¤€ë¹„ ì™„ë£Œ"
      newDc.onopen = () => {
        console.log("â–¶ï¸ DataChannel open");

        // ì²« ë¬¸ì¥ ì •í™•ë„ë¥¼ ìœ„í•´ 3ì´ˆ ë¡œë”© ë” ì£¼ê¸°
        setTimeout(() => {
          // ë§ˆì´í¬ íŠ¸ë™ì„ í™œì„±í™”í•´ì„œ ìŒì„±ì´ ì „ì†¡ë˜ë„ë¡ í•¨
          if (audioTrackRef.current) {
            audioTrackRef.current.enabled = true;
          }
        }, 3000);
      };

      newDc.onclose = () => {
        console.log("â–¶ï¸ DataChannel closed");
      };

      newDc.onerror = (err) => {
        console.error("âŒ DataChannel error:", err);
      };

      // SDP Offer ìƒì„± ë° ì „ì†¡
      const offer = await newPc.createOffer();
      await newPc.setLocalDescription(offer);

      const sdpResponse = await fetch(
        `${import.meta.env.VITE_OPEN_API_URL}?${MODEL}`,
        {
          method: "POST",
          body: offer.sdp,
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`,
            "Content-Type": "application/sdp",
            "OpenAI-Beta": "realtime=v1",
          },
        }
      );

      if (!sdpResponse.ok) {
        throw new Error(
          `SDP exchange failed: ${
            sdpResponse.status
          } ${await sdpResponse.text()}`
        );
      }

      const answerSdp = await sdpResponse.text();
      if (!answerSdp) {
        throw new Error("SDP answer was empty.");
      }
      const answer: RTCSessionDescriptionInit = {
        type: "answer",
        sdp: answerSdp,
      };
      await newPc.setRemoteDescription(answer);
      console.log("âœ… WebRTC ì—°ê²° ì™„ë£Œ"); // ìƒíƒœ ì €ì¥
    } catch (error) {
      console.error("âŒ ì‹œì‘ ì˜¤ë¥˜:", error);
      // alert(
      //   `Failed to start translation: ${
      //     error instanceof Error ? error.message : String(error)
      //   }`
      // );
      // ì‹¤íŒ¨ ì‹œ í´ë¦°ì—…
      if (audioTrackRef.current) audioTrackRef.current.stop();
      if (pcRef.current) pcRef.current.close();
      if (dcRef.current) dcRef.current.close();
    }
  };

  useEffect(() => {
    handleStartTranslate();
  }, []);

  return (
    <div className="flex flex-col items-center pt-5">
      <div className="flex flex-col items-center gap-1 mb-22">
        <strong className="text-[36px] font-medium text-[#1F2937]">
          í†µí™” ì¤‘
        </strong>
        <span className="text-[18px] font-normal text-gray-200">
          ì „í™”ê°€ ì—°ê²°ë˜ì—ˆì–´ìš”
        </span>
      </div>

      {/* ë¡œê³  */}
      <div className="flex justify-center items-center w-[160px] h-[160px] rounded-full mb-8 bg-white/80">
        <div className="flex justify-center items-center w-[128px] h-[128px] rounded-full bg-primary/20">
          <div className="opacity-70">
            <OnCallLogo />
          </div>
        </div>
      </div>

      {/* í†µí™” ì‹œê°„ */}
      <span className="mb-2 text-[24px] font-medium text-gray-200">
        {formatTime(callSeconds)}
      </span>

      {/* ì´ë¦„ */}
      <span className="mb-8 text-[22px] font-medium text-white">ë¦´ë¦¬</span>

      <div className="flex justify-center items-center gap-6 w-[216px] mb-10">
        {callOptions.map((option, idx) => (
          <div key={idx}>
            <button className="flex justify-center items-center w-14 h-14 rounded-full bg-[#E5E7EB]/70">
              {option.icon}
            </button>
          </div>
        ))}
      </div>

      <button
        className="flex justify-center items-center w-[64px] h-[64px] rounded-full bg-primary"
        onClick={() =>
          navigate("/summary", { state: { messages, callSeconds } })
        }
      >
        <Cancel width={24} height={24} />
      </button>
    </div>
  );
}
